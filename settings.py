model = "gpt-3.5-turbo-0613"
# the maximum token length used for truncation in naive_summarizer
token_limit = 3000
# the size of each chunk (in number of characters)
# for the text splitting step of map_reduce summarization
chunk_size = 10000